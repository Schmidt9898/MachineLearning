{"cells":[{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import math\n","\n","\n","data=pd.read_csv('../data/heart_disease.csv')\n","labels=data.values[:,-1]\n","labels[labels>1]=1\n","labels=labels.astype(int)\n","\n","data=data.values[:,:-1]\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Only run before decision boundary visualization\n","#data=data[:,[3,7]]"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["#Standardize data (substract mean divide with std)\n","data= (data - np.mean(data)) / np.std(data)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["sigmoid = lambda x : 1 / (1 + math.exp(-x))\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["class LogisticRegression():\n","\tdef __init__(self):\n","\t\tself.w_hat = None\n","\t\tself.bias = 1\n","\t\tself.learning_rate = 0.01\n","\tdef fit(self,data,labels,max_iterations=500):\n","\t\tself.w_hat = np.zeros(data.shape[1])\n","\t\tbatch_size = 8\n","\t\tN = len(labels)\n","\t\tfor epoch in range(max_iterations):\n","\t\t\t#print(\"epoch\",epoch)\n","\t\t\tfor b in range(int(N/batch_size)+1):\n","\t\t\t\tmini_data = data[b*batch_size:min(batch_size*(b+1),N)]\n","\t\t\t\tmini_labels = labels[b*batch_size:min(batch_size*(b+1),N)]\n","\t\t\t\t\n","\t\t\t\t#print(data[b*batch_size:min(batch_size*(b+1),N)])\n","\t\t\t\t#print(\"\t\tb\",b)\n","\t\t\t\tmini_predict = self.predict(mini_data)\n","\t\t\t\tmini_gradient,bias_error = self.error_gradient(mini_data,mini_labels,mini_predict)\n","\t\t\t\tself.w_hat = self.w_hat - self.learning_rate * mini_gradient\n","\t\t\t\tself.bias = self.bias - self.learning_rate * bias_error\n","\t\t\t\t#print(mini_gradient)\n","\t\t\tif epoch % 100 == 0:\n","\t\t\t\tprint(self.accuracy(labels,self.predict(data)))\n","\n","\tdef sigmoid(self,data):\n","\t\treturn 1 / (1 + np.exp(data))\n","\tdef binary_cross_entropy(self,true,prediction):\n","\t\tN = len(true)\n","\t\tsum = 0\n","\t\tfor i in range(N):\n","\t\t\tsum += true[i] * math.log2(prediction[i]) + (1-true) * math.log2(1 - prediction[i])\n","\t\treturn -1/N * sum\n","\tdef error_gradient(self,data,true,prediction):\n","\t\treturn np.matmul(  np.transpose(data)  ,( prediction - true )) , sum( prediction - true )\n","\n","\t\tpass\n","\tdef predict(self,data):\n","\t\treturn np.asarray(self.sigmoid([ np.dot(self.w_hat,data[i]) + self.bias for i in range(len(data))]))\n","\t\t#self.binary_cross_entropy(np.dot(self.w_hat,data) + self.bias)\n","\tdef accuracy(self,true,prediction):\n","\t\tgood_count = 0.0\n","\t\tfor i in range(len(true)):\n","\t\t\tif true[i] == prediction[i]:\n","\t\t\t\tgood_count+=1\n","\t\t\telse:\n","\t\t\t\tpass\n","\t\t\t\t#print(true[i],prediction[i])\n","\t\treturn good_count / len(true)\n"," "]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def train_test_split(data,labels,p = 0.5):\n","\tp = int(p*len(labels))\n","\ttrain_data = data[0:p]\n","\ttest_data = data[p-1:-1]\n","\ttrain_labels = labels[0:p]\n","\ttest_labels = labels[p-1:-1]\n","\treturn train_data,test_data,train_labels,test_labels"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0\n","0.5578512396694215\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Schmidtlacus\\AppData\\Local\\Temp\\ipykernel_7012\\172799681.py:27: RuntimeWarning: overflow encountered in exp\n","  return 1 / (1 + np.exp(data))\n"]},{"name":"stdout","output_type":"stream","text":["0.5578512396694215\n","0.5578512396694215\n","0.5578512396694215\n","---\n","0.5578512396694215\n","0.47540983606557374\n"]}],"source":["train_data,test_data,train_labels,test_labels = train_test_split(data,labels,0.8)\n","#train_data,train_labels = (data,labels)\n","#test_data,test_labels = (data,labels)\n","lr=LogisticRegression()\n","lr.fit(train_data,train_labels,500)\n","prediction_in=lr.predict(train_data)\n","prediction_out=lr.predict(test_data)\n","print(\"---\")\n","print(lr.accuracy(train_labels,prediction_in))\n","print(lr.accuracy(test_labels,prediction_out))\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Most influential feature 1447.0085748265585\n"]}],"source":["\n","lr.bias\n","\n","print(\"Most influential feature\",max(np.abs(lr.w_hat)))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":4}
